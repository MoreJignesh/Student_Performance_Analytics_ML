 # Project work log

## 2026-01-22
1. open anaconda prompt C:\Users\Jignesh\LearnWithMJ\Data_Science  
2. code .  ---this will launch vs code
3. conda create -p venv python==3.8 -y  this will create 
4. conda activate venv/ ---activating the env
5. git init
6. git step-up did pull and push 
7. setup.py
8. created files as requirement.txt, setup.py, src inti folder
9. pip install -r requirement.txt
10. git push -u origin main --again...
11.
12.
When you open it after few days, follow step 1, 4, 
pip install -r requirements.txt
13.
14.src > Components > __init__.py
15.src > Components > data_ingestion.py 
16.src > Components > data_transformation.py
17.src > Components > model_trainer.py
18.src > Pipeline > train_pipeline.py
19.src > Pipeline > predict_pipeline.py
20.src > Pipeline > __init__.py
21.src > exception.py > custom msg on error function
22.src > logger.py > It will log everything that's performed
23.src > utils.py
24.src > exception.py
25.notebook > data > rawdatafile.csv
26.notebook > EDA.ipynd
27.notebook > Model_training.ipynd
28.
29.updated data_ingestion file with class methods
30.
31.
32.
33.
34.
35. Research - EDA > Research - Model Training


This project will cover as below :

Setup project with Github
Data Ingestion
Data transformation
Model Trainer
Model evaluation
Model deployment
CI/CD pipeliene - github actiona
deployment AWS















------------------

Total Score is continouse Value -  Regression problem , also use random forest 
Categorical  features : One hot encoding >> Standardization >>> Normalization (all should be in pipeline) --comes from sklearn
Numerical Features : Standard Scaller
Many many categorical feature: Target Guided ordinal encoding


Streamlit : This will help you to provide a web platform in few lines for your Python project.